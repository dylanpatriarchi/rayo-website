---
title: "Real-Time Transaction Analysis Pipeline"
publishedAt: "2024-04-10"
summary: "Ingegnerizzazione di una pipeline di stream processing per l'anomaly detection ad alta frequenza su volumi transazionali critici."
industry: "Fintech / Banking"
impact: "Low Latency"
---

## La Sfida Ingegneristica

La gestione di flussi transazionali ad alta velocità richiede sistemi capaci di prendere decisioni complesse in finestre temporali estremamente ridotte. I sistemi tradizionali basati su regole cablate ("hard-coded rules") mostravano limiti evidenti nel bilanciare accuratezza e velocità, generando frizione operativa e falsi allarmi. La necessità era migrare verso un approccio probabilistico capace di adattarsi a pattern emergenti.

## Architettura: Event-Driven Analysis

Abbiamo implementato una pipeline di **Stream Processing** che analizza ogni evento in tempo reale, mantenendo uno stato contestuale per ogni entità monitorata.

### Ingestion & Processing
Il core del sistema è basato su un'architettura Kappa:
1.  **Message Backbone**: Utilizzo di **Apache Kafka** come l'unica fonte di verità per i log delle transazioni, garantendo durability e replayability.
2.  **Stateful Processing**: **Apache Flink** gestisce finestre temporali (sliding windows) per aggregare metriche in tempo reale (es. "frequenza eventi negli ultimi 5 minuti" vs "media storica").

### Deep Anomaly Detection
Invece di classificazioni binarie, utilizziamo un approccio non supervisionato basato su **Autoencoder**:
-   Il modello apprende la rappresentazione latente compressa del comportamento "normale".
-   In fase di inferenza, calcola il "Reconstruction Error" tra l'input e l'output ricostruito.
-   Un errore elevato indica una deviazione significativa dal pattern appreso (anomalia), senza la necessità di aver visto quella specifica tipologia di anomalia in precedenza.

## Ottimizzazione della Latenza

Il vincolo critico era la latenza di inferenza sincrona.
-   **Model Serving**: Deployment su **Triton Inference Server** con ottimizzazione TensorRT per massimizzare il throughput su GPU.
-   **Feature Store**: Utilizzo di Redis come low-latency store per il recupero istantaneo delle feature aggregare (online serving).

## Risultati Tecnici

Il deploy in produzione ha validato la robustezza dell'architettura:
-   **Latenza Deterministica**: Tempi di risposta p99 costantemente sotto i 50ms, inclusi network trip e feature retrieval.
-   **Adattabilità**: Il modello dimostra capacità di generalizzazione su nuovi pattern non presenti nel training set iniziale.
-   **Scalabilità**: L'architettura disaccoppiata permette di scalare indipendentemente i nodi di calcolo (Flink) e i nodi di inferenza (Kubernetes/GPU).
